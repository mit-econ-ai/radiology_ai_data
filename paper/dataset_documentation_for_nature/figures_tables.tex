\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{images/designs.pdf}    
    \caption{Experimental designs}
    \label{fig:experiment_design}
\end{figure}

\begin{table}[ht]
    \centering
    \caption{Summary statistics\label{tab:summary_statistics}}
    \input{table_summary_frag.tex}
    \noindent\begin{minipage}[t]{1\columnwidth}%
    {\scriptsize{}Note: This table presents summary statistics of the
    experimental data. The first panel pools across all three designs
    and the remaining three panels separate for each of the three designs
    respectively. Decision is an indicator for whether treatment/follow-up
    is recommended, correct decision is an indicator for whether the decision
    matches the diagnostic standard, deviation from diagnostic standard is the absolute
    difference between the reported probability and the diagnostic standard,
    deviation from AI is the absolute difference between the expert's
    reported probability and the AI's reported probability, active time
    is measured in minutes.}%
    \end{minipage}
\end{table}

\begin{table}[H]
    \centering
    \caption{Diagnostic Standard Quality}
    \input{tables/groundtruth_quality_table}
    \label{tab:diag_standard_quality}
    \noindent\begin{minipage}[t]{1\columnwidth}%
    {\scriptsize{}Note: For each of the pre-registered pathology groups, this table shows the average prevalence, the share of cases where we can reject that $\sum_{r=1}^{R}\frac{\pi_{r}(\omega_{i}=1|s_{i,r}^{E})}{R}=0.5$ at the 5\% level, and the average number of reads per case for both the Mount Sinai ground truth diagnostic standard labels and the experiment leave-one-out ground truth diagnostic standard.}%
    \end{minipage}
\end{table}

\begin{table}[H]
    \centering
    \caption{Diagnostic Standard Effort}
    \input{tables/groundtruth_quality_table2}
    \label{tab:diag_standard_effort}
    \noindent\begin{minipage}[t]{1\columnwidth}%
    {\scriptsize{}Note: For each of the five Mount Sinai radiologists we compute the average and standard deviation of time spent per case and the number of clicks per case. In addition, we compute the average agreement with the original read as labeled by the CheXbert algorithm.}%
    \end{minipage}
\end{table}

\begin{figure}[H]%
    \caption{Comparing AI performance to radiologists}%
    \label{fig:compare_performance}%
    \centering
    \subfloat[\centering RMSE Radiologists and AI]{{\includegraphics[width=7cm]{images/rmse_top_level_IN_NAI.pdf} }}%
    \qquad
    \subfloat[\centering AUROC Radiologists and AI]{{\includegraphics[width=7cm]{images/auroc_top_level_IN_NAI.pdf} }}%
\end{figure}
\begin{footnotesize}
  \noindent Note: These histograms show distributions of two different accuracy measures of radiologist assessments alongside the AI's accuracy. The left graph shows the distribution of the RMSE while the right shows the distribution of the average AUROC. Both distributions are shrunk to the grand mean using empircal Bayes. These measures are for each radiologist and include the top-level pathologies. The dotted line is the average measure of the AI algorithm for the corresponding distribution. Only the assessments where contextual history information is available for the radiologists but not the AI prediction are considered. 
\end{footnotesize}

\begin{figure}[H] 
\caption{AI Influence\label{fig:ai-influence}}
    \begin{center}
    \includegraphics[width=0.8\textwidth]{images/ai_influence.pdf}
    \end{center}
\end{figure}

\begin{figure}[H]
    \caption{Clinical History Influence\label{fig:ch-influence}}
    \begin{center}
    \includegraphics[width=0.8\textwidth]{images/ph_influence.pdf}
    \end{center}
\end{figure}