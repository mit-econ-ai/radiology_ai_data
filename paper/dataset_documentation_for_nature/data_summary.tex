\subsection*{Data Summary \& Preliminary Analysis}

The following sections intend to discuss possible uses of the dataset
for future research. 

\subsubsection*{Summary Statistics}

In this section, we present some preliminary statistics on radiologists’ reported probability and decisions (table \ref{tab:summary_statistics}) and the effort exerted by the radiologists. The values have been reported across all the pre-registered groups: a) Top-level with AI, including the top-level pathologies of cardiomedistinal abnormality and airspace opacity. b) Pooled with AI, including all the pathologies with AI predictions while excluding abnormality and support device hardware. c) Pooled, including all pathologies with and without AI predictions. d) Abnormal, including cases marked as abnormal. As shown in the table \ref{tab:summary_statistics}, there is consistency in the reported statistics across the different designs.

In the experiment, for the top-level pathologies, the radiologists’ probability ranges from $\sim$0.21 to $\sim$0.25 across the three designs, with an average of 0.23. The low probability of treating a patient across the experiment points to the low prevalence rate of the pathologies considered. The radiologists make the correct decision approximately 70\% of the time, with radiologists from design 3 performing above average by 9\%. The average time spent by the radiologists on each case is $\sim$2.8 minutes, and the average across the designs ranges from 2.5 - 3 minutes. On average, the radiologists clicked 45 times when entering their predictions for each case. The measures of active time and clicks are relevant to study the effort exerted by the radiologists in the experiment.

The quality of the AI is assessed through the AI accuracy variable that measures the absolute deviation of the AI prediction from the diagnostic standard probability. For top-level and pooled with AI cases, the deviation is quite small, but the deviation is much larger for abnormal cases.
%0.56

\subsubsection*{Post experiment questionnaire}


At the end of the experiment, radiologists filled a survey based on their experience with the AI tool and clinical history used in making the assessments. These assessments are helpful in understanding the heterogeneity in radiologists’ qualities. Their responses allow the analysis of the extent to which AI and CH affect the assessment, decision-making and effort exerted in the diagnosis process. This information allows the exploration of questions across the quantitative assessments and qualitative beliefs.

AI influence (figure \ref{fig:ai-influence}): we try to evaluate the role played by AI in influencing radiologists actions. We find that while $\sim$45\% of radiologists agree that AI influences the assessment of a pathology's presence, only $\sim$28\% believe that it influences the diagnosis decision. Radiologists were split on their views of AI influencing their decision regarding follow-up treatment. This inconsistent treatment of AI signals by radiologists is important in understanding the costs faced by radiologists in integrating AI signals in decision-making. Consequently, one can study cognitive dissonance exhibited by the radiologists when it comes to using AI with the aid of this post-experiment questionnaire.

Clinical history influence (figure \ref{fig:ch-influence}): contrastingly, radiologists agreed to the influence of clinical history on all three fronts of assessment, decision-making and effort exertion. Clinical history is considered to be a critical component in diagnostic radiology, as it helps radiologists to narrow down to specific regions in the X-ray. Concurrently, its availability is believed to introduce cognitive biases like anchoring bias, attribution bias and framing bias (\cite{Yapp2022-tf}). Given these doubts about the benefits of clinical history, the radiologists’ probabilities and treatment decisions across different information environments in the dataset can be uses to study its importance. The radiologists in their answers to the question, "In what types of cases did the patient history matter?", frequently refer to certain conditions, as show in figure \ref{fig:ch-influence}. 