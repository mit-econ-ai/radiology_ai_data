% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@MISC{Agarwal2023-dn,
  title        = "Combining Human Expertise with Artificial Intelligence:
                  Experimental Evidence from Radiology",
  author       = "Agarwal, N and Moehring, A and Rajpurkar, P and Salz, T",
  abstract     = "Although Artificial intelligence (AI) algorithms have matched
                  the performance of human experts on several predictive tasks,
                  humans may access valuable contextual information that has
                  not been incorporated into AI predictions. Humans that
                  combine AI predictions with their own information could
                  therefore out-perform both humans alone or AI alone. Using an
                  experiment on professional radiologists that varies the
                  availability of AI support and contextual information, we
                  show that (i) providing AI predictions does not uniformly
                  increase …",
  publisher    = "blueprintcdn.com",
  year         =  2023,
}


@ARTICLE{Yapp2022-tf,
  title     = "The effect of clinical history on diagnostic imaging
               interpretation - A systematic review",
  author    = "Yapp, Kehn E and Brennan, Patrick and Ekpo, Ernest",
  abstract  = "RATIONALE AND OBJECTIVES: To provide updated information on the
               effect of clinical history on diagnostic image interpretation
               and to provide study methodology and design recommendations for
               future studies assessing the effect of clinical history on
               diagnostic image performance. MATERIALS AND METHODS: A
               literature search of Medline, Embase, Scopus, Web of Science,
               and the Cochrane Central Register of Controlled Trials (CENTRAL)
               databases was conducted from database inception to July 21,
               2020. Studies comparing diagnostic imaging performance with and
               without clinical history, using observers reading images under
               both conditions that used an independent reference standard were
               included. RESULTS: Twenty-two studies met the inclusion
               criteria, with 15 showing clinical history improved diagnostic
               performance. One study reported a decrease in diagnostic
               performance with clinical history and the remaining six studies
               found no significant change in performance. Two studies used the
               free response paradigm with both reporting clinical history
               increased location sensitivity, decreased specificity and had no
               overall change in diagnostic performance. The disease spectrum
               of included cases was largely unreported and a balanced reading
               design was not used in 19 studies. CONCLUSION: Most published
               studies found that clinical history improved diagnostic
               performance. More recent studies accounting for abnormality
               location and multiple abnormalities showed an increase in false
               positives and no significant change in overall diagnostic
               performance with clinical history.",
  journal   = "Acad. Radiol.",
  publisher = "Elsevier BV",
  volume    =  29,
  number    =  2,
  pages     = "255--266",
  month     =  feb,
  year      =  2022,
  keywords  = "Clinical history; diagnostic performance; free response
               paradigm; imaging interpretation; interpretive bias;Datasheet",
  language  = "en"
}

@INPROCEEDINGS{Alberdi2005-lm,
  title     = "Automation bias and system design: a case study in a medical
               application",
  booktitle = "2005 The {IEE} and {MOD} {HFI} {DTC} Symposium on People and
               Systems - Who Are We Designing For (Ref. No. 2005/11078)",
  author    = "Alberdi, E and Ayton, P and Povyakalo, A A and Strigini, L",
  abstract  = "We discuss the results of an interdisciplinary study of
               computer-aided decision making in cancer screening. We found
               evidence of ``automation bias'' - roughly, over-reliance on
               automation, which may degrade users' performance. While such
               effects are well known, they have not been previously reported
               for this application with expert clinicians, and are not
               generally considered in the literature. One lesson from our
               study was that these potentially important effects easily go
               unnoticed with common assessment methods. Implications for
               designers of computer aided decision making include that: a) it
               may be necessary to calibrate tool design for a range of
               different levels of user skills; b) an ``expert system''
               approach to computerised aid design - building a ``better
               replica'' of a human expert - may be counterproductive by making
               the aid weak in those very areas where humans need help; c) HCI
               design risks focusing on usability of the physical
               human-computer interface, but the critical issues in design
               concern the cognitive effects (e.g. changes of decision
               thresholds) a computer tool may have on users; d) users'
               subjective assessments of a computer aid may be misleading:
               people may judge a tool helpful when their decision-making
               performance is actually being hampered.",
  publisher = "ieeexplore.ieee.org",
  pages     = "53--60",
  month     =  nov,
  year      =  2005,
  keywords  = "Datasheet"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Ng2016-nm,
  title        = "What artificial intelligence can and can't do right now",
  author       = "Ng, Andrew",
  abstract     = "Many executives ask me what artificial intelligence can do.
                  They want to know how it will disrupt their industry and how
                  they can use it to reinvent their own companies. But lately
                  the media has sometimes painted an unrealistic picture of the
                  powers of AI.(Perhaps soon it will take over the world!) AI
                  is already transforming web search, advertising, e-commerce,
                  finance, logistics, media, and more. As the founding lead of
                  the Google Brain team, former director of the Stanford
                  Artificial Intelligence Laboratory, and now overall lead of
                  Baidu's AI …",
  publisher    = "wtw.org",
  year         =  2016,
  howpublished = "\url{http://www.w-t-w.org/de/wp-content/uploads/2016/11/Andrew-Ng-What-AI-Can-and-Can%E2%80%99t-Do.pdf}",
  note         = "Accessed: 2023-5-26",
  keywords     = "Datasheet"
}

@ARTICLE{Longoni2019-mo,
  title     = "Resistance to Medical Artificial Intelligence",
  author    = "Longoni, Chiara and Bonezzi, Andrea and Morewedge, Carey K",
  abstract  = "Abstract. Artificial intelligence (AI) is revolutionizing
               healthcare, but little is known about consumer receptivity to AI
               in medicine. Consumers are reluctant",
  journal   = "J. Consum. Res.",
  publisher = "Oxford Academic",
  volume    =  46,
  number    =  4,
  pages     = "629--650",
  month     =  may,
  year      =  2019,
  keywords  = "Datasheet",
  language  = "en"
}

@ARTICLE{Ridderikhoff1999-ef,
  title     = "Who is afraid of the system? Doctors' attitude towards
               diagnostic systems",
  author    = "Ridderikhoff, J and van Herk, B",
  abstract  = "Although physicians indicate a need for diagnostic support,
               devices that may provide such support, i.e. computer-aided
               systems are not in widespread use. Practising physicians often
               blame this on the computer. We have tested this idea by asking
               physicians to solve a number of patient problems with the help
               of a diagnostic decision support system in a realistic
               environment. As we expected, the use of the computer was not
               found to be an obstacle. However, the support part of the
               system, which was meant to stimulate the user's thoughts and to
               prompt him to review his conclusions, turned out to be
               problematic. The critiquing function of the system hardly seemed
               appreciated by the participants, and only rarely influenced
               their diagnostic judgement. Sources of additional information
               were ignored. We have come to the conclusion that the
               combination of physicians and computer-aided diagnosis deserves
               further and thorough exploration.",
  journal   = "Int. J. Med. Inform.",
  publisher = "Elsevier",
  volume    =  53,
  number    =  1,
  pages     = "91--100",
  month     =  jan,
  year      =  1999,
  keywords  = "Datasheet",
  language  = "en"
}

@ARTICLE{Medow2010-jh,
  title     = "Are residents' decisions influenced more by a decision aid or a
               specialist's opinion? A randomized controlled trial",
  author    = "Medow, Mitchell A and Arkes, Hal R and Shaffer, Victoria A",
  abstract  = "BACKGROUND: Physicians are reluctant to use decision aids
               despite their ability to improve care. A potential reason may be
               that physicians do not believe decision aid advice. OBJECTIVE:
               To determine whether internal medicine residents lend more
               credence to contradictory decision aid or human advice. DESIGN:
               Randomized controlled trial. Residents read a scenario of a
               patient with community-acquired pneumonia and were asked whether
               they would admit the patient to the intensive care unit or the
               floor. Residents were randomized to receive contrary advice from
               either a referenced decision aid or an anonymous pulmonologist.
               They were then asked, in light of this new information, where
               they would admit the patient. PARTICIPANTS: One hundred eight
               internal medicine residents. MEASUREMENTS: The percentage of
               residents who changed their admission location and the change in
               confidence in the decision. MAIN RESULTS: Residents were more
               likely to change their original admission location (OR 2.3, 95\%
               CI 1.04 to 5.1, P = 0.04) and to reduce their confidence in the
               decision (adjusted difference between means -12.9\%, 95\% CI
               -3.0\% to -22.8\%, P = 0.011) in response to the referenced
               decision aid than to the anonymous pulmonologist. Confidence in
               their decision was more likely to change if they initially chose
               to admit the patient to the floor. CONCLUSIONS: In a
               hypothetical case of community-acquired pneumonia, physicians
               were influenced more by contrary advice from a referenced
               decision aid than an anonymous specialist. Whether this holds
               for advice from a respected specialist or in actual practice
               remains to be studied.",
  journal   = "J. Gen. Intern. Med.",
  publisher = "Springer",
  volume    =  25,
  number    =  4,
  pages     = "316--320",
  month     =  apr,
  year      =  2010,
  keywords  = "Datasheet",
  language  = "en"
}
